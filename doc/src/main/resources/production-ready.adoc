== Production-ready requirements

Strictly speaking, the service demo implementation is not ready for commercial operation a little bit less than completely.

=== Most important issues

* first of all, Bulk mailing service is usually implemented as a completely separated enterprise-level service with quite dedicated functions.
** All other services of the application won't try to send messages by oneself and only delegate such activity to it.
Usually, such service is responsible, for example, for the right authorization on the SMTP servers with SPF, DKIM, DMARC headers, handling several queues of messages with different urgency and so on.
Quite often, third-party providers of such service are used.
** So, as a minimum one-third of the required functionality has to be moved out from the service under consideration.
* username / real password storing (even in the protected storage) and passing it to IMAP server in absolutely unacceptable.
Taking into account the chosen architecture, the next alternatives are available:
** authorization based on OAuth and similar approaches.
Unfortunately, support for this authentication way is not a requirement under the IMAP standard
** configuring the IMAP server to copy / re-sending incoming and outcoming mails to special folders, available to the service.
The method and the principle possibility of such customization vary greatly from server to server.

=== Business requirements

Really, the business requirements for the process are hardly defined.
At a minimum, the next features have to be discussed:

* the user should be able to configure several policies about which emails to which recipients have to be monitored with specific params
* notification to the user about the end of the monitoring some mail with the ability to prolong the process.
Usually, it is the link in the mail.
* ability for the notification recipient to stop the process considering the specific mail or notification service at all.
Usually, it is the link in the mail.
* customizable templates for different types of notifications
* gathering some statistic by clients/mail types and so on

Developing this concept we inevitably enter the territory of CRM systems.

===  Technical improvements

* split service as minimum into two parts: notifier service and bulk mailing service.
** In fact, gathering data from IMAP boxes and dealing with the database is quite different by IO nature activities.
In case of a high load, it makes sense to split them and to implement the first one based on the NIO approach.
Also, separated mail gate is a quite good candidate to be located separately into DMZ.
** so, it makes sense to considering architecture, based on three services, connected by queues of messages: notifier, bulk sender and mail gate

* distributed processing
** apply message queue for processing user's accounts (one message per one account) and batches of mails
** apply distributed log system (kafka, for example) for processing notifications.
In this case, a distributed log is better than a message queue due to already available the partitioning feature.
Also, similar functionality can be implemented based on database (some rough implementation is performed by the demo project) but less effectively
** if we are planning to deal with big data volumes it is better to think about data sharding in advance.
It is a quite good case for sharding, because we don't deal with long-living data.
* even in the case of one service, splitting the whole business process into several tasks, activated asynchronously by internal events one after another.
Different execution (threads count, for example) and retry policies (count, pauses for example) for each task.
* take into account different timezones of user/recipients and service
* general for database access
** optimize all concerning tables for high concurrent access.
For oracle, it includes, for example, setting INITRANS and MAXTRANS parameters.
The same for sequences (but I prefer to use UUID for primary keys) if they are used.
** batching for data insert
** use more advanced tools such as *Liquibase*, for setup and updating the schema.

* general for distributed systems
** proper logging (each line is an event) suitable for processing by ELK-like systems.
Separate logging of multi-line exceptions with references from the main log.
** in case of splitting into several service support of distributed logging (traceId / spanId).
Integration with a corresponding analysis tool, Zipkin for example.
** retry policy for all remote calls
** gathering and providing metrics about remote calls, common internal services, volumes of processing data and so on.
Aggregation of data (Dropwizard Metrics, for example) and publishing for analysis (Prometheus, for example).
** providing data about the current state of the instance (Spring Actuator, Java Melody)
** ...

* integration with chosen deployment and services orchestration system (Kubernetes, for example)



